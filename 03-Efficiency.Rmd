# Efficiency

## Main Resources
[Efficient R Programming by Colin Gillespie and Robin Lovelace](https://csgillespie.github.io/efficientR): This book goes into great depth on working efficiently in R.

[How to speed up R code:  an introduction](https://arxiv.org/pdf/1503.00855v1.pdf): This resource is a little old (from 2015) but still contains some useful background on how to speed up R.

## Processing

### For Loops
Never grow a vector, preallocate the size of objects used to store results.
```{r preallocate, eval=FALSE}
out <- integer(50)

for (i in 1:50) {
    out[i] <- rpois(1, 10)
}
```

Use [descriptive indices](https://onunicornsandgenes.blog/2018/12/01/using-r-the-best-thing-ive-changed-about-my-code-in-years/) in loops to make them easier to understand.
```{r descriptive_indice, eval=FALSE}
# First attempt
for (i in 1:ncol(geno)) {
   for (j in 1:nrow(geno)) {
        output[i,j] <- do_something(geno[j, i])
   }
}

# Second attempt
n_markers <- ncol(geno)
n_ind <- nrow(geno)
for (marker_ix in 1:n_markers) {
   for (individual_ix in 1:n_ind) {
        output[individual_ix, marker_ix] <-
            do_something(geno[individual_ix, marker_ix])
   }
}
```

If you really need to a grow a vector:

```{r tweet_grow_vec, out.width="60%", echo=FALSE}
knitr::include_graphics("images/tweet_grow_vec.png")
```


Parallel Processing [need to do some research on this, see [future](https://cran.r-project.org/web/packages/future/index.html) package].

[Rcpp](http://adv-r.had.co.nz/Rcpp.html) - loops are faster using this.


### Avoiding Loops
Avoid loops if you can, use functional programming, e.g. `purrr::map()`. **Note**: loops are not necessarily slower but leave more room for the user to write them inefficiently.


### Finding Slow Parts of Code
Profiling code - e.g. using [`profviz`](https://rstudio.github.io/profvis) (now built into the RStudio IDE)

Benchmarking - e.g. with the [`bench`](http://bench.r-lib.org) package or the [`microbenchmark`](https://cran.r-project.org/web/packages/microbenchmark/index.html) package.


## Memory Management

### Efficiently Extracting Data from Databases
Extract only data necessary for analysis from databases [**reference Emily Moore's SMRA paper detailing efficient SQL queries**].

If you can use the [`odbc`](https://db.rstudio.com/odbc) package to connect to databases, you can use [`dbplyr`](https://db.rstudio.com/dplyr) to write efficient SQL queries using dplyr code. Once you are sure your query will extract what you need (view generated SQL code from dplyr using `show_query()`), the data can be downloaded into R using [`collect()`](https://dplyr.tidyverse.org/reference/compute.html).


### Temporary Objects
Remove *temporary* objects as you go along in an analysis, particularly if those objects take up a lot of memory (e.g. temporary large dataframes). The [objectremover](https://cran.r-project.org/web/packages/objectremover/index.html) RStudio addin may help with this.


### Caching
`memoise` - more advanced.


## Importing and Exporting Data
For critical analyses, I still find the base R functions (e.g. `read.csv()`) to be most reliable but `readr::read_csv()` is much faster.

[vroom](https://github.com/jimhester/vroom) - experimental package using the [ALTREP](https://svn.r-project.org/R/branches/ALTREP/ALTREP.html) framework but potentially extremely fast package for reading delimited files.

[writexl](https://cran.r-project.org/web/packages/writexl/index.html) - the fastest package for writing to Excel and has no dependencies.

